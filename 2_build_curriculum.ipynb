{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "VbO4BQKwUyiT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21711,
     "status": "ok",
     "timestamp": 1738544074080,
     "user": {
      "displayName": "Vince Angelo Chavez",
      "userId": "08933368134424002002"
     },
     "user_tz": -480
    },
    "id": "VbO4BQKwUyiT",
    "outputId": "70b606c9-dfb9-45cf-b99a-2900cdd5c210"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "/content/drive/Shareddrives/dnn_lambda-1405/dnn_lambda-1405\n"
     ]
    }
   ],
   "source": [
    "# Load the Drive helper and mount\n",
    "from google.colab import drive\n",
    "\n",
    "# This will prompt for authorization.\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "%cd /content/drive/Shareddrives/dnn_lambda-1405/dnn_lambda-1405"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ihs1zIPADPbX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1738506319742,
     "user": {
      "displayName": "Vince Angelo Chavez",
      "userId": "08933368134424002002"
     },
     "user_tz": -480
    },
    "id": "ihs1zIPADPbX",
    "outputId": "12f96d42-0184-4e18-ce1e-2b34eb425b58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/Shareddrives/dnn_lambda-1405/dnn_lambda-1405\n"
     ]
    }
   ],
   "source": [
    "%cd /content/drive/Shareddrives/dnn_lambda-1405/dnn_lambda-1405"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "N7nkP37zU1Vf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4720,
     "status": "ok",
     "timestamp": 1738544082648,
     "user": {
      "displayName": "Vince Angelo Chavez",
      "userId": "08933368134424002002"
     },
     "user_tz": -480
    },
    "id": "N7nkP37zU1Vf",
    "outputId": "d195f692-ebfe-460d-8bd7-cabe5581dc47"
   },
   "outputs": [
    {
     "ename": "error",
     "evalue": "incomplete escape \\U at position 28",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconda\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minstall conda-forge::cupy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mD:\\Users\\vange\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:2480\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[1;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[0;32m   2478\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_ns\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_local_scope(stack_depth)\n\u001b[0;32m   2479\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m-> 2480\u001b[0m     result \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2482\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[0;32m   2483\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[0;32m   2484\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[0;32m   2485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[1;32mD:\\Users\\vange\\anaconda3\\Lib\\site-packages\\IPython\\core\\magics\\packaging.py:30\u001b[0m, in \u001b[0;36mis_conda_environment.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Path(sys\u001b[38;5;241m.\u001b[39mprefix, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconda-meta\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhistory\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mexists():\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe python kernel does not appear to be a conda environment.  \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     28\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease use ``\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mpip install`` instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     29\u001b[0m     )\n\u001b[1;32m---> 30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\Users\\vange\\anaconda3\\Lib\\site-packages\\IPython\\core\\magics\\packaging.py:128\u001b[0m, in \u001b[0;36mPackagingMagics.conda\u001b[1;34m(self, line)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;129m@line_magic\u001b[39m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;129m@is_conda_environment\u001b[39m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconda\u001b[39m(\u001b[38;5;28mself\u001b[39m, line):\n\u001b[0;32m    123\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Run the conda package manager within the current kernel.\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \n\u001b[0;32m    125\u001b[0m \u001b[38;5;124;03m    Usage:\u001b[39;00m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;124;03m      %conda install [pkgs]\u001b[39;00m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 128\u001b[0m     conda \u001b[38;5;241m=\u001b[39m _get_conda_like_executable(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_command(conda, line)\n",
      "File \u001b[1;32mD:\\Users\\vange\\anaconda3\\Lib\\site-packages\\IPython\\core\\magics\\packaging.py:53\u001b[0m, in \u001b[0;36m_get_conda_like_executable\u001b[1;34m(command)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# Otherwise, attempt to extract the executable from conda history.\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# This applies in any conda environment.\u001b[39;00m\n\u001b[0;32m     52\u001b[0m history \u001b[38;5;241m=\u001b[39m Path(sys\u001b[38;5;241m.\u001b[39mprefix, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconda-meta\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhistory\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mread_text(encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 53\u001b[0m match \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msearch(\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m^#\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*cmd:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*(?P<command>.*\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexecutable\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms[create|install]\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     55\u001b[0m     history,\n\u001b[0;32m     56\u001b[0m     flags\u001b[38;5;241m=\u001b[39mre\u001b[38;5;241m.\u001b[39mMULTILINE,\n\u001b[0;32m     57\u001b[0m )\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m match:\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m match\u001b[38;5;241m.\u001b[39mgroupdict()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcommand\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mD:\\Users\\vange\\anaconda3\\Lib\\re\\__init__.py:177\u001b[0m, in \u001b[0;36msearch\u001b[1;34m(pattern, string, flags)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msearch\u001b[39m(pattern, string, flags\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    175\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Scan through string looking for a match to the pattern, returning\u001b[39;00m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;124;03m    a Match object, or None if no match was found.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 177\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _compile(pattern, flags)\u001b[38;5;241m.\u001b[39msearch(string)\n",
      "File \u001b[1;32mD:\\Users\\vange\\anaconda3\\Lib\\re\\__init__.py:307\u001b[0m, in \u001b[0;36m_compile\u001b[1;34m(pattern, flags)\u001b[0m\n\u001b[0;32m    301\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m    302\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe re.TEMPLATE/re.T flag is deprecated \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    303\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is an undocumented flag \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    304\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwithout an obvious purpose. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    305\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDon\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt use it.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    306\u001b[0m             \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m)\n\u001b[1;32m--> 307\u001b[0m p \u001b[38;5;241m=\u001b[39m _compiler\u001b[38;5;241m.\u001b[39mcompile(pattern, flags)\n\u001b[0;32m    308\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m&\u001b[39m DEBUG:\n\u001b[0;32m    309\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m p\n",
      "File \u001b[1;32mD:\\Users\\vange\\anaconda3\\Lib\\re\\_compiler.py:745\u001b[0m, in \u001b[0;36mcompile\u001b[1;34m(p, flags)\u001b[0m\n\u001b[0;32m    743\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m isstring(p):\n\u001b[0;32m    744\u001b[0m     pattern \u001b[38;5;241m=\u001b[39m p\n\u001b[1;32m--> 745\u001b[0m     p \u001b[38;5;241m=\u001b[39m _parser\u001b[38;5;241m.\u001b[39mparse(p, flags)\n\u001b[0;32m    746\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    747\u001b[0m     pattern \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Users\\vange\\anaconda3\\Lib\\re\\_parser.py:979\u001b[0m, in \u001b[0;36mparse\u001b[1;34m(str, flags, state)\u001b[0m\n\u001b[0;32m    976\u001b[0m state\u001b[38;5;241m.\u001b[39mflags \u001b[38;5;241m=\u001b[39m flags\n\u001b[0;32m    977\u001b[0m state\u001b[38;5;241m.\u001b[39mstr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m\n\u001b[1;32m--> 979\u001b[0m p \u001b[38;5;241m=\u001b[39m _parse_sub(source, state, flags \u001b[38;5;241m&\u001b[39m SRE_FLAG_VERBOSE, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    980\u001b[0m p\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mflags \u001b[38;5;241m=\u001b[39m fix_flags(\u001b[38;5;28mstr\u001b[39m, p\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mflags)\n\u001b[0;32m    982\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m source\u001b[38;5;241m.\u001b[39mnext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mD:\\Users\\vange\\anaconda3\\Lib\\re\\_parser.py:460\u001b[0m, in \u001b[0;36m_parse_sub\u001b[1;34m(source, state, verbose, nested)\u001b[0m\n\u001b[0;32m    458\u001b[0m start \u001b[38;5;241m=\u001b[39m source\u001b[38;5;241m.\u001b[39mtell()\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 460\u001b[0m     itemsappend(_parse(source, state, verbose, nested \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    461\u001b[0m                        \u001b[38;5;129;01mnot\u001b[39;00m nested \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m items))\n\u001b[0;32m    462\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sourcematch(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    463\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Users\\vange\\anaconda3\\Lib\\re\\_parser.py:862\u001b[0m, in \u001b[0;36m_parse\u001b[1;34m(source, state, verbose, nested, first)\u001b[0m\n\u001b[0;32m    859\u001b[0m     group \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    860\u001b[0m sub_verbose \u001b[38;5;241m=\u001b[39m ((verbose \u001b[38;5;129;01mor\u001b[39;00m (add_flags \u001b[38;5;241m&\u001b[39m SRE_FLAG_VERBOSE)) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    861\u001b[0m                \u001b[38;5;129;01mnot\u001b[39;00m (del_flags \u001b[38;5;241m&\u001b[39m SRE_FLAG_VERBOSE))\n\u001b[1;32m--> 862\u001b[0m p \u001b[38;5;241m=\u001b[39m _parse_sub(source, state, sub_verbose, nested \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    863\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m source\u001b[38;5;241m.\u001b[39mmatch(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    864\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m source\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmissing ), unterminated subpattern\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    865\u001b[0m                        source\u001b[38;5;241m.\u001b[39mtell() \u001b[38;5;241m-\u001b[39m start)\n",
      "File \u001b[1;32mD:\\Users\\vange\\anaconda3\\Lib\\re\\_parser.py:460\u001b[0m, in \u001b[0;36m_parse_sub\u001b[1;34m(source, state, verbose, nested)\u001b[0m\n\u001b[0;32m    458\u001b[0m start \u001b[38;5;241m=\u001b[39m source\u001b[38;5;241m.\u001b[39mtell()\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 460\u001b[0m     itemsappend(_parse(source, state, verbose, nested \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    461\u001b[0m                        \u001b[38;5;129;01mnot\u001b[39;00m nested \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m items))\n\u001b[0;32m    462\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sourcematch(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    463\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Users\\vange\\anaconda3\\Lib\\re\\_parser.py:544\u001b[0m, in \u001b[0;36m_parse\u001b[1;34m(source, state, verbose, nested, first)\u001b[0m\n\u001b[0;32m    541\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    543\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m this[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 544\u001b[0m     code \u001b[38;5;241m=\u001b[39m _escape(source, this, state)\n\u001b[0;32m    545\u001b[0m     subpatternappend(code)\n\u001b[0;32m    547\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m this \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m SPECIAL_CHARS:\n",
      "File \u001b[1;32mD:\\Users\\vange\\anaconda3\\Lib\\re\\_parser.py:398\u001b[0m, in \u001b[0;36m_escape\u001b[1;34m(source, escape, state)\u001b[0m\n\u001b[0;32m    396\u001b[0m escape \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m source\u001b[38;5;241m.\u001b[39mgetwhile(\u001b[38;5;241m8\u001b[39m, HEXDIGITS)\n\u001b[0;32m    397\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(escape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m10\u001b[39m:\n\u001b[1;32m--> 398\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m source\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincomplete escape \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m escape, \u001b[38;5;28mlen\u001b[39m(escape))\n\u001b[0;32m    399\u001b[0m c \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(escape[\u001b[38;5;241m2\u001b[39m:], \u001b[38;5;241m16\u001b[39m)\n\u001b[0;32m    400\u001b[0m \u001b[38;5;28mchr\u001b[39m(c) \u001b[38;5;66;03m# raise ValueError for invalid code\u001b[39;00m\n",
      "\u001b[1;31merror\u001b[0m: incomplete escape \\U at position 28"
     ]
    }
   ],
   "source": [
    "conda install conda-forge::cupy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b818b5d-5d50-42b1-a66e-9b5763d4c1d5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13195,
     "status": "ok",
     "timestamp": 1738544097612,
     "user": {
      "displayName": "Vince Angelo Chavez",
      "userId": "08933368134424002002"
     },
     "user_tz": -480
    },
    "id": "9b818b5d-5d50-42b1-a66e-9b5763d4c1d5",
    "outputId": "1162b512-edc6-45f2-a564-604d05d1700f",
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m figure\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nn\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader, Dataset\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import cmath as cm\n",
    "import random\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "#from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "\n",
    "import sklearn\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tabulate import tabulate\n",
    "from tqdm import tqdm\n",
    "\n",
    "#Import the module containing the class pole\n",
    "import import_ipynb\n",
    "import module\n",
    "from module import unif_pole, T1, T2, Einput\n",
    "from module import m1, m2, T1, T2, Nreal, Nimag, hbarc, seerealimagpart\n",
    "from module import Einput, Ereal, Eimag, Erealfar, Eimagfar, labelz, inspect, NEpoints\n",
    "from module import skip_duplicate, export_data, import_data, get_traintest\n",
    "\n",
    "from datetime import datetime\n",
    "start_time = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af1fa819-2b3d-43f3-955f-eda4ea86ef11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch\n",
      "  Downloading pytorch-1.0.2.tar.gz (689 bytes)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: pytorch\n",
      "  Building wheel for pytorch (setup.py): started\n",
      "  Building wheel for pytorch (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for pytorch\n",
      "Failed to build pytorch\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × python setup.py bdist_wheel did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [6 lines of output]\n",
      "      Traceback (most recent call last):\n",
      "        File \"<string>\", line 2, in <module>\n",
      "        File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "        File \"C:\\Users\\vange\\AppData\\Local\\Temp\\pip-install-61zyiwgr\\pytorch_e6e1bde5ef654bc8976d564f397ac4af\\setup.py\", line 15, in <module>\n",
      "          raise Exception(message)\n",
      "      Exception: You tried to install \"pytorch\". The package named for PyTorch is \"torch\"\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for pytorch\n",
      "ERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (pytorch)\n"
     ]
    }
   ],
   "source": [
    "pip install pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "448d7bff-ba16-4dbc-a672-6189ea7664e1",
   "metadata": {
    "executionInfo": {
     "elapsed": 279,
     "status": "ok",
     "timestamp": 1738544100202,
     "user": {
      "displayName": "Vince Angelo Chavez",
      "userId": "08933368134424002002"
     },
     "user_tz": -480
    },
    "id": "448d7bff-ba16-4dbc-a672-6189ea7664e1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalize(x_array):\n",
    "    #input must be an array\n",
    "    #output: normalized array\n",
    "\n",
    "    delx = max(x_array)\n",
    "\n",
    "    if delx != 0:\n",
    "        norm_array = np.array(list(map(lambda x: x/delx, x_array)))\n",
    "    else:\n",
    "        norm_array = x_array\n",
    "\n",
    "    return norm_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ddb4af45-14b4-4e25-b350-347e3bee6dd5",
   "metadata": {
    "executionInfo": {
     "elapsed": 5986,
     "status": "ok",
     "timestamp": 1738544110258,
     "user": {
      "displayName": "Vince Angelo Chavez",
      "userId": "08933368134424002002"
     },
     "user_tz": -480
    },
    "id": "ddb4af45-14b4-4e25-b350-347e3bee6dd5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "curriculum =  #1-32\n",
    "retain_label = 17\n",
    "labels = [19]\n",
    "#directory = f'curriculum{curriculum:02d}_training'\n",
    "#directory1 = f'curriculum{curriculum:02d}_training'\n",
    "#directory = 'full_lambda-1405_dataset'\n",
    "directory = 'dataset_sigma-plus_pion-minus'\n",
    "#directory = 'lambda_1405_full_dataset'\n",
    "directory1 = f'250313_lambda-1405_full_curriculum{curriculum:02d}'\n",
    "if not os.path.isdir(directory1):\n",
    "    os.mkdir(directory1)\n",
    "#print(f\"Curriculum: {curriculum:02d}\")\n",
    "#Generate curriculum\n",
    "#Note: we used Nreal = 2000 and Nimag = 2000, giving us 4*(2000*2000)=16,000,000 data points\n",
    "Einput = []\n",
    "Einput00 = pickle.load(open(os.path.join(directory,f'Einput{retain_label:02d}.pkl'),'rb'))\n",
    "Einput.extend(Einput00)\n",
    "for add_data in labels: #range(start_label,last_label + 1):\n",
    "    xx = add_data\n",
    "    EinputXX = pickle.load(open(os.path.join(directory,'Einput{:02d}.pkl'.format(xx)),'rb'))\n",
    "    Einput.extend(EinputXX)\n",
    "    del EinputXX\n",
    "\"\"\"\n",
    "for add_data in range(20,23):\n",
    "    xx = add_data\n",
    "    EinputXX = pickle.load(open(os.path.join(directory,'Einput{:02d}.pkl'.format(xx)),'rb'))\n",
    "    Einput.extend(EinputXX)\n",
    "    del EinputXX\n",
    "\"\"\"\n",
    "Einput = np.array(Einput)\n",
    "pickle.dump (Einput, open(os.path.join(directory1,'Einput_curr{:02d}.pkl'.format(curriculum)),'wb'), protocol=4)\n",
    "del Einput\n",
    "\n",
    "ModEsq = pickle.load(open(os.path.join(directory,f'ModEsq{retain_label:02d}.pkl'),'rb'))\n",
    "for add_data in labels: #range(start_label,last_label + 1):\n",
    "    xx = add_data\n",
    "    ModEsqXX = pickle.load(open(os.path.join(directory,f'ModEsq{xx:02d}.pkl'),'rb'))\n",
    "    #ModEsqXX = list(map(lambda x: normalize(x), ModEsqXX))\n",
    "    #print(max(ModEsqXX[0]))\n",
    "    ModEsq = ModEsq + ModEsqXX\n",
    "    del ModEsqXX\n",
    "\"\"\"\n",
    "for add_data in range(20,23):\n",
    "    xx = add_data\n",
    "    ModEsqXX = pickle.load(open(os.path.join(directory,f'ModEsq{xx:02d}.pkl'),'rb'))\n",
    "    #ModEsqXX = list(map(lambda x: normalize(x), ModEsqXX))\n",
    "    #print(max(ModEsqXX[0]))\n",
    "    ModEsq = ModEsq + ModEsqXX\n",
    "    del ModEsqXX\n",
    "\"\"\"\n",
    "\n",
    "ModEsq = np.array(ModEsq)\n",
    "\n",
    "#ModEsqnorm = np.array(list(map(lambda x: normalize(x), ModEsq)))\n",
    "#ModEsq = np.array(ModEsqnorm)\n",
    "\n",
    "pickle.dump (ModEsq, open(os.path.join(directory1,'ModEsq_curr{:02d}.pkl'.format(curriculum)),'wb'), protocol=4)\n",
    "del ModEsq\n",
    "\n",
    "labelout = pickle.load(open(os.path.join(directory,f'labelout{retain_label:02d}.pkl'),'rb'))\n",
    "for add_data in labels: #range(start_label,last_label + 1):\n",
    "    xx = add_data\n",
    "    labeloutXX = pickle.load(open(os.path.join(directory,'labelout{:02d}.pkl'.format(xx)),'rb'))\n",
    "    labelout = labelout + labeloutXX\n",
    "    del labeloutXX\n",
    "\n",
    "\"\"\"\n",
    "for add_data in range(20,23):\n",
    "    xx = add_data\n",
    "    labeloutXX = pickle.load(open(os.path.join(directory,'labelout{:02d}.pkl'.format(xx)),'rb'))\n",
    "    labelout = labelout + labeloutXX\n",
    "    del labeloutXX\n",
    "\"\"\"\n",
    "\n",
    "labelout = np.array(labelout)\n",
    "pickle.dump (labelout, open(os.path.join(directory1,'labelout_curr{:02d}.pkl'.format(curriculum)),'wb'), protocol=4)\n",
    "del labelout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "babf2f4d-c1b4-458a-89b2-c564788bb7cd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 255,
     "status": "ok",
     "timestamp": 1738548924071,
     "user": {
      "displayName": "Vince Angelo Chavez",
      "userId": "08933368134424002002"
     },
     "user_tz": -480
    },
    "id": "babf2f4d-c1b4-458a-89b2-c564788bb7cd",
    "outputId": "f0ee4510-0c6b-4172-a361-8cfb07039cdf",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 1, 2, 60)\n",
      "Size of training dataset: ((16000, 1, 2, 60), (16000,))\n",
      "Size of testing dataset: ((4000, 1, 2, 60), (4000,))\n",
      "Test output values: [0 1]\n",
      "Test output count per value: [2000 2000]\n"
     ]
    }
   ],
   "source": [
    "# If Nshuffle=0, it is understood that the testing dataset is to be prepared.\n",
    "# Otherwise, it is the training dataset, and Nshuffle determines shuffling times.\n",
    "out = directory1\n",
    "# import prepared dataset\n",
    "inputtraining_Einp = pickle.load(open(os.path.join(out, 'Einput_curr{:02d}.pkl'.format(curriculum)), 'rb'))\n",
    "inputtraining_MOd = pickle.load(open(os.path.join(out, 'ModEsq_curr{:02d}.pkl'.format(curriculum)), 'rb'))\n",
    "#inputtraining = np.reshape(inputtraining_MOd,(inputtraining_MOd.shape[0], 1, -1))\n",
    "inputtraining = np.float32(np.stack((inputtraining_Einp, inputtraining_MOd), axis=1))\n",
    "inputtraining = np.reshape(inputtraining,(inputtraining.shape[0], 1, 2, -1))\n",
    "#inputtraining.reshape(inputtraining.shape[0], -1)\n",
    "#print(inputtraining.shape)\n",
    "#inputtraining = pickle.load(open(os.path.join(out, 'ModEsq_curr{:02d}.pkl'.format(curriculum)), 'rb'))\n",
    "#inputtraining = np.float32(np.array(inputtraining))\n",
    "#inputtraining = torch.from_numpy(inputtraining).type(torch.float)\n",
    "print(inputtraining.shape)\n",
    "\n",
    "outputtraining = pickle.load(open(os.path.join(out, 'labelout_curr{:02d}.pkl'.format(curriculum)), 'rb'))\n",
    "outputtraining = np.array(outputtraining)\n",
    "#outputtraining = outputtraining[:, np.newaxis]\n",
    "#outputtraining = torch.from_numpy(outputtraining).type(torch.long)\n",
    "\n",
    "\"\"\"\n",
    "#-------------------------------------------\n",
    "#This part is for HADRON2025\n",
    "print(outputtraining.size)\n",
    "#outputtraining_new = np.zeros(outputtraining.size)\n",
    "for i in range(outputtraining.size):\n",
    "    label = outputtraining[i]\n",
    "    if label in [1, 2, 3]:\n",
    "        outputtraining[i] = 1\n",
    "    elif label in [6, 8, 9]:\n",
    "        outputtraining[i] = 2\n",
    "    elif label in [4, 5, 7]:\n",
    "        outputtraining[i] = 3\n",
    "    elif label in [10, 11, 12]:\n",
    "        outputtraining[i] = 4\n",
    "\n",
    "#outputtraining = outputtraining_new\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "#----------------------------------------------\n",
    "# This part is for converting the numbered labels to an array (classification --> regression)\n",
    "labels = [[0, 0, 0], [1, 0, 0], [0, 1, 0], [0, 0, 1], [2, 0, 0], [0, 2, 0], [0, 0, 2],\n",
    "         [1, 1, 0], [1, 0, 1], [0, 1, 1], [3, 0, 0], [0, 3, 0], [0, 0, 3], [2, 1, 0],\n",
    "          [2, 0, 1], [1, 2, 0], [0, 2, 1], [1, 0, 2], [0, 1, 2], [1, 1, 1]]\n",
    "outputtrainingnew = []\n",
    "for i in range(outputtraining.size):\n",
    "    label = outputtraining[i]\n",
    "    outputtrainingnew.append(labels[label])\n",
    "\n",
    "outputtraining = np.float32(np.asarray(outputtrainingnew))\n",
    "#----------------------------------------------\n",
    "\"\"\"\n",
    "\n",
    "#\"\"\"\n",
    "# This part is for the Lambda1405 paper\n",
    "for i in range(outputtraining.size):\n",
    "    label = outputtraining[i]\n",
    "    if label == 17:\n",
    "        outputtraining[i] = 0\n",
    "    elif label == 19:\n",
    "        outputtraining[i] = 1\n",
    "    elif label == 1:\n",
    "        outputtraining[i] = 2\n",
    "    elif label == 1:\n",
    "        outputtraining[i] = 3\n",
    "    #elif label == 8:\n",
    "    #    outputtraining[i] = 4\n",
    "\n",
    "#\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "# This part is for the binary classification Lambda1405 paper\n",
    "outputtrainingnew = []\n",
    "for i in range(outputtraining.size):\n",
    "    label = outputtraining[i]\n",
    "    if label == 7:\n",
    "        outputtrainingnew.append([0,1])\n",
    "    else:\n",
    "        outputtrainingnew.append([1,0])\n",
    "\n",
    "outputtraining = np.float32(np.asarray(outputtrainingnew))\n",
    "\n",
    "#\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "for i in range(outputtraining.size):\n",
    "    label = outputtraining[i]\n",
    "    if label in [1, 2, 3]:\n",
    "        outputtraining[i] = 1\n",
    "    elif label in [4, 5, 6]:\n",
    "        outputtraining[i] = 2\n",
    "    elif label in [7, 8, 9]:\n",
    "        outputtraining[i] = 3\n",
    "    elif label in [10, 11, 12]:\n",
    "        outputtraining[i] = 4\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# shuffle the imported data\n",
    "# split training set with testing set\n",
    "\n",
    "train_plots, test_plots, train_labels, test_labels = train_test_split(inputtraining, outputtraining, test_size=0.2, random_state=42, stratify=outputtraining)\n",
    "\n",
    "#train_plots, test_plots, train_labels, test_labels = train_test_split(train_test_plots, train_test_labels, test_size=0.2, random_state=42, stratify=train_test_labels)\n",
    "\n",
    "pickle.dump(train_plots, open(os.path.join(out, 'train_plots_curr{:02d}.pkl'.format(curriculum)), 'wb'), protocol=4) #pickle.dump(train, open(os.path.join(out, 'chainer_train.pkl'), 'wb'), protocol=4)\n",
    "pickle.dump(test_plots, open(os.path.join(out, 'test_plots_curr{:02d}.pkl'.format(curriculum)), 'wb'), protocol=4) #pickle.dump(train, open(os.path.join(out, 'chainer_train.pkl'), 'wb'), protocol=4)\n",
    "pickle.dump(train_labels, open(os.path.join(out, 'train_labels_curr{:02d}.pkl'.format(curriculum)), 'wb'), protocol=4) #pickle.dump(train, open(os.path.join(out, 'chainer_train.pkl'), 'wb'), protocol=4)\n",
    "pickle.dump(test_labels, open(os.path.join(out, 'test_labels_curr{:02d}.pkl'.format(curriculum)), 'wb'), protocol=4) #pickle.dump(train, open(os.path.join(out, 'chainer_train.pkl'), 'wb'), protocol=4)\n",
    "pickle.dump(test_plots, open(os.path.join(out, 'valid_plots_curr{:02d}.pkl'.format(curriculum)), 'wb'), protocol=4) #pickle.dump(train, open(os.path.join(out, 'chainer_train.pkl'), 'wb'), protocol=4)\n",
    "pickle.dump(test_labels, open(os.path.join(out, 'valid_labels_curr{:02d}.pkl'.format(curriculum)), 'wb'), protocol=4) #pickle.dump(train, open(os.path.join(out, 'chainer_train.pkl'), 'wb'), protocol=4)\n",
    "\n",
    "\n",
    "\n",
    "#test = chainer.datasets.TupleDataset(X_test, y_test)\n",
    "# split training set with the testing set\n",
    "#pickle.dump(test, open(os.path.join(out, 'chainer_test_curr{:02d}.pkl'.format(curriculum)), 'wb'), protocol=4)#pickle.dump(test, open(os.path.join(out, 'chainer_test.pkl'), 'wb'), protocol=4)\n",
    "\n",
    "print(f'Size of training dataset: {train_plots.shape, train_labels.shape}')\n",
    "print(f'Size of testing dataset: {test_plots.shape, test_labels.shape}')\n",
    "print(f\"Test output values: {np.unique(test_labels, return_counts=True)[0]}\")\n",
    "print(f\"Test output count per value: {np.unique(test_labels, return_counts=True)[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d19c1f9-7fc6-4fb3-903b-dca6455d70dc",
   "metadata": {
    "id": "0d19c1f9-7fc6-4fb3-903b-dca6455d70dc"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
